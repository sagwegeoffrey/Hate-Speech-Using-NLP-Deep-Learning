{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hate Speech Detection task on Social Media(Twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q70i05iGyIbS",
    "outputId": "c78795d0-c28a-462e-9abc-c539c4fa2c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 27 21:07:22 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzmNE0R5y4e0",
    "outputId": "d9dfffbf-a6e0-4a15-ed64-59bff5558ae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.7/669.7 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --quiet transformers==4.1.1\n",
    "!pip install --quiet pytorch-lightning==1.1.1\n",
    "!pip install --quiet tokenizers==0.9.4\n",
    "!pip install --quiet sentencepiece==0.1.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "un6mcl0R43p5",
    "outputId": "17a4483d-1f2e-4947-ccce-bc61d9c19c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/PyTorchLightning/pytorch-lightning\n",
      "  Cloning https://github.com/PyTorchLightning/pytorch-lightning to /tmp/pip-req-build-5_vtedj_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-req-build-5_vtedj_\n",
      "  Resolved https://github.com/PyTorchLightning/pytorch-lightning to commit 9b69d512d97707124e2865883397f2a1fd859c2a\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  Encountered 31 file(s) that should have been pointers, but weren't:\n",
      "        .notebooks/course_UvA-DL/01-introduction-to-pytorch.ipynb\n",
      "        .notebooks/course_UvA-DL/02-activation-functions.ipynb\n",
      "        .notebooks/course_UvA-DL/03-initialization-and-optimization.ipynb\n",
      "        .notebooks/course_UvA-DL/04-inception-resnet-densenet.ipynb\n",
      "        .notebooks/course_UvA-DL/05-transformers-and-MH-attention.ipynb\n",
      "        .notebooks/course_UvA-DL/06-graph-neural-networks.ipynb\n",
      "        .notebooks/course_UvA-DL/07-deep-energy-based-generative-models.ipynb\n",
      "        .notebooks/course_UvA-DL/08-deep-autoencoders.ipynb\n",
      "        .notebooks/course_UvA-DL/09-normalizing-flows.ipynb\n",
      "        .notebooks/course_UvA-DL/10-autoregressive-image-modeling.ipynb\n",
      "        .notebooks/course_UvA-DL/11-vision-transformer.ipynb\n",
      "        .notebooks/course_UvA-DL/12-meta-learning.ipynb\n",
      "        .notebooks/course_UvA-DL/13-contrastive-learning.ipynb\n",
      "        .notebooks/flash_tutorials/electricity_forecasting.ipynb\n",
      "        .notebooks/flash_tutorials/image_classification.ipynb\n",
      "        .notebooks/flash_tutorials/tabular_classification.ipynb\n",
      "        .notebooks/flash_tutorials/text_classification.ipynb\n",
      "        .notebooks/lightning_examples/augmentation_kornia.ipynb\n",
      "        .notebooks/lightning_examples/barlow-twins.ipynb\n",
      "        .notebooks/lightning_examples/basic-gan.ipynb\n",
      "        .notebooks/lightning_examples/cifar10-baseline.ipynb\n",
      "        .notebooks/lightning_examples/datamodules.ipynb\n",
      "        .notebooks/lightning_examples/finetuning-scheduler.ipynb\n",
      "        .notebooks/lightning_examples/mnist-hello-world.ipynb\n",
      "        .notebooks/lightning_examples/mnist-tpu-training.ipynb\n",
      "        .notebooks/lightning_examples/reinforce-learning-DQN.ipynb\n",
      "        .notebooks/lightning_examples/text-transformers.ipynb\n",
      "        .notebooks/lightning_examples/warp-drive.ipynb\n",
      "        .notebooks/templates/img-classify.ipynb\n",
      "        .notebooks/templates/simple.ipynb\n",
      "        .notebooks/templates/titanic.ipynb\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting croniter<1.4.0,>=1.3.0\n",
      "  Downloading croniter-1.3.8-py2.py3-none-any.whl (18 kB)\n",
      "Collecting inquirer<5.0,>=2.10.0\n",
      "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (6.0)\n",
      "Collecting lightning-utilities<2.0,>=0.7.0\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (23.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (1.22.4)\n",
      "Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (1.13.1+cu116)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (2023.3.0)\n",
      "Collecting websockets<12.0\n",
      "  Downloading websockets-10.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (3.1.2)\n",
      "Collecting fastapi<0.89.0\n",
      "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-cloud>=0.5.31\n",
      "  Downloading lightning_cloud-0.5.32-py3-none-any.whl (545 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m546.0/546.0 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil<7.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (5.9.4)\n",
      "Collecting uvicorn<2.0\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics<2.0,>=0.7.0\n",
      "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<4.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (2.27.1)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (4.11.2)\n",
      "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (1.26.15)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (5.7.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (4.5.0)\n",
      "Collecting deepdiff<8.0,>=5.7.0\n",
      "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (13.3.2)\n",
      "Collecting starlette<2.0\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting arrow<3.0,>=1.2.0\n",
      "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dateutils<2.0\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (8.1.3)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (1.1.1)\n",
      "Requirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.9/dist-packages (from lightning==2.1.0.dev0) (1.10.7)\n",
      "Collecting starsessions<2.0,>=1.2.1\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting websocket-client<3.0\n",
      "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.9/dist-packages (from arrow<3.0,>=1.2.0->lightning==2.1.0.dev0) (2.8.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning==2.1.0.dev0) (2.4)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from dateutils<2.0->lightning==2.1.0.dev0) (2022.7.1)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting starlette<2.0\n",
      "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting readchar>=3.0.6\n",
      "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Collecting blessed>=1.19.0\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-editor>=1.0.4\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2<5.0->lightning==2.1.0.dev0) (2.1.2)\n",
      "Collecting pyjwt\n",
      "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting fastapi[all]\n",
      "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from lightning-cloud>=0.5.31->lightning==2.1.0.dev0) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<4.0->lightning==2.1.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<4.0->lightning==2.1.0.dev0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<4.0->lightning==2.1.0.dev0) (2.0.12)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich<15.0,>=12.3.0->lightning==2.1.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich<15.0,>=12.3.0->lightning==2.1.0.dev0) (2.14.0)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from starsessions<2.0,>=1.2.1->lightning==2.1.0.dev0) (2.1.2)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning->lightning==2.1.0.dev0) (0.18.3)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning->lightning==2.1.0.dev0) (2.11.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1.0.dev0) (22.2.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.9/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning==2.1.0.dev0) (0.2.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning==2.1.0.dev0) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.9/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning==2.1.0.dev0) (67.6.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (1.51.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (1.4.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (1.8.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (3.19.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (0.40.0)\n",
      "Collecting fastapi[all]\n",
      "  Downloading fastapi-0.94.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.94.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.93.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.91.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.90.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.90.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.89.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading fastapi-0.89.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart>=0.0.5\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.2.1\n",
      "  Downloading orjson-3.8.8-cp39-cp39-manylinux_2_28_x86_64.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx>=0.23.0\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1\n",
      "  Downloading ujson-5.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting email-validator>=1.1.1\n",
      "  Downloading email_validator-1.3.1-py2.py3-none-any.whl (22 kB)\n",
      "Collecting dnspython>=1.15.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 KB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (1.3.1)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (6.1.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.5.0\n",
      "  Downloading httptools-0.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 KB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.18.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->lightning==2.1.0.dev0) (3.2.2)\n",
      "Building wheels for collected packages: lightning\n",
      "  Building wheel for lightning (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for lightning: filename=lightning-2.1.0.dev0-py3-none-any.whl size=1834704 sha256=079db454b0657613071df9667e4bd391787d0627e7ab269445aefb65057ee265\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iv3hj5pb/wheels/71/cd/86/0fcffbab9766493276c053f69e3cda436783f811f28fecc3ab\n",
      "Successfully built lightning\n",
      "Installing collected packages: rfc3986, python-editor, websockets, websocket-client, uvloop, ujson, sniffio, readchar, python-multipart, python-dotenv, pyjwt, orjson, ordered-set, multidict, lightning-utilities, httptools, h11, frozenlist, dnspython, blessed, async-timeout, yarl, uvicorn, torchmetrics, inquirer, email-validator, deepdiff, dateutils, croniter, arrow, anyio, aiosignal, watchfiles, starlette, httpcore, aiohttp, starsessions, httpx, fastapi, lightning-cloud, lightning\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 anyio-3.6.2 arrow-1.2.3 async-timeout-4.0.2 blessed-1.20.0 croniter-1.3.8 dateutils-0.6.12 deepdiff-6.3.0 dnspython-2.3.0 email-validator-1.3.1 fastapi-0.88.0 frozenlist-1.3.3 h11-0.14.0 httpcore-0.16.3 httptools-0.5.0 httpx-0.23.3 inquirer-3.1.3 lightning-2.1.0.dev0 lightning-cloud-0.5.32 lightning-utilities-0.8.0 multidict-6.0.4 ordered-set-4.1.0 orjson-3.8.8 pyjwt-2.6.0 python-dotenv-1.0.0 python-editor-1.0.4 python-multipart-0.0.6 readchar-4.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.22.0 starsessions-1.3.0 torchmetrics-0.11.4 ujson-5.7.0 uvicorn-0.21.1 uvloop-0.17.0 watchfiles-0.18.1 websocket-client-1.5.1 websockets-10.4 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnqY-1ZF5byK",
    "outputId": "b2e4e1fb-7c71-47f5-dca0-4e9e06f35ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8iMSV8d6tmM"
   },
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrGqKakC6KJo",
    "outputId": "69d35e6d-28cc-4271-a6a6-fe8e20726298"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import random\n",
    "import operator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "V_E8NPjlVfQ1",
    "outputId": "356c2a3e-9a5e-4693-c8a8-cf4d163a16db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-782b136a-2f23-4382-8aeb-285a479ab251\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-782b136a-2f23-4382-8aeb-285a479ab251\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving HateSpeech.csv to HateSpeech.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-XydUU4VO-P",
    "outputId": "0a7df9cd-04c8-4759-d2dd-9ef1d82a7c7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count  hate_speech  offensive_language  neither  class  \\\n",
      "0          3            1                   1        2      2   \n",
      "1          3            1                   1        2      2   \n",
      "2          3            1                   1        2      2   \n",
      "3          3            1                   1        2      2   \n",
      "4          3            1                   1        2      2   \n",
      "...      ...          ...                 ...      ...    ...   \n",
      "50170      4            2                   1        1      0   \n",
      "50171      4            2                   1        1      0   \n",
      "50172      5            3                   0        2      0   \n",
      "50173      4            2                   0        2      0   \n",
      "50174      4            3                   1        0      0   \n",
      "\n",
      "                                                   tweet  \n",
      "0      kindly say bickering to kikuyus and kalenjins....  \n",
      "1      kindly remind them that we do not have thoroug...  \n",
      "2      kindly look at moses' statement. where has he ...  \n",
      "3      kindly like this page>>>wtf fun facts maasai a...  \n",
      "4      kindly kikuyus humble yourselves in 2022 and t...  \n",
      "...                                                  ...  \n",
      "50170                      this issa plot to kill luhyas  \n",
      "50171  this is why i will not vote raila in luos are ...  \n",
      "50172  this is why i hate luos even the ones calling ...  \n",
      "50173  this is the biggest bullshit no hit bid agains...  \n",
      "50174  this is not breaking news kikuyus kill for pow...  \n",
      "\n",
      "[50175 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    " \n",
    "df = pd.read_csv(io.BytesIO(uploaded['HateSpeech.csv']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sdmhrv1EOqig"
   },
   "source": [
    "### Load data\n",
    "\n",
    "Note that I will only use two of the columns: 'tweet' and 'class' (i.e. the label). The other columns (sentiment towards Election, Hate_Speech are superfluous to the current (simple) task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IIcaUFgmOX2R"
   },
   "outputs": [],
   "source": [
    "def load_data(path, sample_size=5, cols=['tweet', 'class'], label=None):\n",
    "    \"\"\"Helper function that loads data from a given path into a pandas\n",
    "       DataFrame, using only the specified cols. Also prints basic info\n",
    "       about the dataset size and displays a sample of the rows. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(path, sep='\\t', usecols=cols)\n",
    "    \n",
    "    print(f\"\\nThere are {df.shape[0]} tweets in the {label} dataset.\")\n",
    "    print(\"\\nHere's a sample:\\n\")\n",
    "    display(df.sample(sample_size))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MJd7C6KtTT8N"
   },
   "outputs": [],
   "source": [
    "# Are there any duplicates?\n",
    "assert len(df['tweet'].drop_duplicates()) == len(df['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kHe5Z1NS1fg"
   },
   "source": [
    "### Quick inspection / visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "z1j1vY-nS8cq",
    "outputId": "958191e6-1794-402b-d9b4-ed13494c928e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4rElEQVR4nO3debxd873/8ddbYi5iiFwSJLdSfqGtakpc1WsW6or2KgklQaW9RWlxTSWGKqqtUqq0UnGLSNEmV2NIldIaY6g5lRJNYkiI2UXD5/fH97uTlZN9ztk5Z0/nnPfz8diPs9Z3TZ+1z9qf/dlrf/daigjMzMzMzCxZrtEBmJmZmZk1ExfIZmZmZmYFLpDNzMzMzApcIJuZmZmZFbhANjMzMzMrcIFsZmZmZlZQlwJZ0kBJkR/b57YxefzYGmznxmqts8Ltbi9ppqQPJf15GZc9WtL8HPf3JK0n6V5JH+S23lWOtSrPu6R1Jb0raZVqxdaJWLrkc1hY3yqSTpM0phrrq2B7e+TtDVzG5U7L+73PMi43JC+7faHtiryuocuyrhbrXT+vd+9OrOOOHMc6HV1HXs/bkmZVMF+HnvtliOPf8vq3qMX6rbbKvYdJOja3jcnjsyS93c56utVxIOkHkl7Pz8PXWkzrdB5Yxlj2z9vr08r0DuXJZYzhm5JOK4w3pPbp7hpxBvmkBmxzmXSgoDoc+DgwLj+WxcnASsBo4Frgy8DWwHXAKODDZVxfe/6U1/u/nVzPbsBdEfFu50PqtK76HJasQjpuxlRpfe3ZI29v4DIuV3o+713G5Ybk7W2/jMu1Z/283r1bm6GC1/IZpH16s3phtamjz32l/i2vf4sard8a70hSrmtLzY6Dap9wqGB7qwLHAW8ABwJ/bDFLu3mgyvbP2+tTp+2V802WvdawZRURNX+Q3gyCdIAHMJRUDARwbJ5nFvB2Hh6ap12Rx6/I4z8DXgKeBHYA7ie9sZ3SYjt3AjcBbwP/A6yYp28D3JPb/waMarHc3cAfgJfL7MMGwO+A14AXgJ8AKwKn5WVLjyvKLPt54L683ZnA2Nx+R4tlx7QYn5XnOwSYAbyTY9wyt5fmvwb4a47tqDxtk7zN/8vtd7VY5ljSiyyAL+dpe+Tx7wArAD8E5gKvA78B+hb26Wrg6DwcwDPAVfl/fCuwSjv7XnzOb8r/x6sBtXIMdbvnsLBvs1rEfBrwF+DFPP2E3D4M+GQePqud/Sq77TLPT5A+KP8cWJD39UlgxzJxnpbn36e9/3uZ137xsT2LX9M/BJ4HZgPb5WXWAMYD84BXgMuAVcvE03K9YwoxjgeeBc4nvak+D7xPyh+XAL1aHD/r5LgC+H1+/t8AzmvleNwwP99vA+flv6VjbWfSMfpejn8isFq55z7P/xvS8fVefu6/lNvXBW7L636TdCz2zdNOBJ4D3gJuAf61EH/xMbAeOd6P6jwKr5db8jG5DnBq6fjO88xi8XvltsCj+diZT8pjZY8DYLN8PL2ZXw+nkPMtqeh7MbdflJc5rcVr5IJ8PO9Nev+bn19TzwJfb/G6/Fs+rt/Kr8X98/x/J+eoMvs+AniMlMseB0YU9neJ/NFiuXJ5YC5wb57+89z+L8B/5OHDWnsd5fayOYil3+9nldmP0jylPLkn6b3lnfx3l9xe+j+VzTfAMXnbT7A4X44pDJced7D4uLkLmEI776d+VPh6rMtGFv/zfp9fADfQsQL5j6Q3vCC9ML+Tl1sIrF3YzkLSJ84b8vi3gLWAV4Gn8oviVtKZxS1Y8k38XHLx1WIf7szznwj8Ks97BrA58FAePxLYusVya5MKj5eAb5DeVAPYMT9KiW0k6aznr/P0S0gv5tKL6Ja87RmkF/9KhefwJdJZ7FKBswIpmX2UY/oG8Oscz6LnnZR8/wlcnaf9Kj9365E+nQYpuZxGepO+Ps+3HOmFu0keLz13PwBuzsMHtrPvpee89Jw+kMe3I33wKL05rNEdn8MWx8j+eb4n8z5sDpzD4je2yXn4aODreXi3dvar7LaBQXn+0vE7EvhMHp9EOjN1NrBrmThPY+kCean/e4tlVmXxa/a6vL11Wfyavhv4bh6+rfAc/jOv9xzSMfKjMvGclJf7U17voEKMc/JztROwe+F/eFWefkBexx0sXSC/DRxFeuMPYMMy2/5tnnYW6c1z0Zsl6YPMd4CxwE/ztJPLPfd5/v8GDgO+nY+Bt/L/8Nt53tPz9EtJb/Kjc/vEvN4XgQfz81o89kdS5oOFH837oPwHykWFX55nFovfKyfn4/XQfIz/tJXjYA1Scfo26f3wf/P0Q4B+pJz3Qn6NPEX5AvnOvJ3/l19bY/M27yHlvA1b5IXTgel5+CEWF/q/K7PfmwAfAE/n9T6dxzdh6fy4bgV5YCKpRliRVJQGqbA/Ow9v0trrKK+zbA5i6ff7/yizL6fl6fsAn8hx3Es60XF//h+sRxv5Bvh0Hn4iP9cvlo4B0nvc7Dw+knbeTxt9THflR71f9DcCB5CKjnNZ9gJ5Z2BwHi6dzfufPP6ZwnZK0z6ex28Avkj5pPOdwnIPtRL/x/L0v+TxFfOB+EAevzFPH1hm2T3ztNIZv13y+Hl5fNGZpzx+bOmFkMfPayXuLVlcqH0/z1sqUjYAjsjDN5HejD+X5yktc2wh9jfzPr4K3JrbHyizzTfztGHA3wsxB/BCHh6Zx09pa98Lz/ndeVrpLOmBLHmm7Y7u+By2OEbWKe1roa10vI4incW4mdR95ArSm9Fq7exXW/+/0hmi7fN4P9LZjb/lafsDy5eJ8zSWLpCX+r+XWW4fCm+4LV7Tu+bx98jHFOnDTsvYHy2z3iXyRIsYv1VoG0l68y+u75w87Q6WLpBLH3ZKZ56WepMhnfGdnYdXIOWDWXl8B9IZ5OL2Jrby3PcCJpDeRIvzb8ri4/7PpDfpHfMyv2nl/74WLY59P7rWg8V58V7S+93OpA9GxXw2i8XvlT/Mx971pCJv09zeMgdunsevyuOl99HfkM7cBvC9PO2w4uu18Br5VCHOc0k5o3j8Dc/TApiTh8/K44fmYz2Av5bZ71KuPaxFDIdTJj+2WLZcHjg8t+2an5+bc8x3kL8hbud11GoOoo33+zz9tDx9n0IcLR9fpo18QyqYA/hai+ex9P98HIgyx81S76eNPqa78qOufYmyiaRi4xst2j8kvYCg9b49r5M+1UH6OqK0HIVlAdTib9GVpKK6ZFZh+IVWtlsS7UyvZNmOruMY0ldpkM7gPgd8Ko8vyH8X5r+9IuIiSU8B/05KgCdLGlJmvb8mFWPnkhLDrwvTFpLepEvPcanP+u6korFoqRgK09ra93LL3UIqgiEVIutVsJ5KNNNzWFRuf/5M+iB5IOn18FPS2aD3SG8wb0mLDu9y+9XWtpfYXkS8LGkz0hmWrUlnWYeQzuy2p63/+6JNVLh8cdmXSPte8v4yrrf4Wv4JqZ/3fqQzsBeQztBWEhOU36e2nE3q8nAo6cPbtYXttYx5F+AgUteuH5LOSn0RWCkibpQ0LM8zHDhe0i6FZQ8gfXiC9L99t8z6rWt6JSL+ANDOD+2OJ32tvg3peDtR0gBaPw7ayqHtHTsv5Hg2JX3r8QipKP9P0pno4mvq9fx30ft1RHyYc1Zbr6eO5Phy896Z/x5N+lbtN6Tn59OkYrmo3OsIWs9BHXmN/QCYVhh/ivQhBSp772yptfbO5i4rqPuP9CLiQ9LBsnqLSbOAlST9F+lF3xnDJB2XtwPpU+M9pINnOOnszOakT1n9K4j5bdILbpikE0h9oZcDplYQyz2kIu9QSV8nfbqkwmUhdUuBdCZxQ1IBc2FEvNbWQpK+QUqaM/NjOdKZwpamkN7E/4uUGG7I7TcCvUlfQ21Iet6+nqeVK5DL6dC+R8SLEfGH/Hiwo+spaMbnsOhNUjG8saQDJG0UEW+QuiMNBx4mHX/9SUm1lPzb2q+2tl3a730kfVHSJ0hveG+T+rlC+uFLtZS2t52kkZJWbmf+G0mF7F7ARqSzLfu1sd7PSBrVzpUoViCdidq74qjbdjswQNJZpLPCLXOp8va+0qJ9iee+0L4q6X+77aIVpF/B70n6OvWJ3Lw+6fmB9L/dgPQB7pSIeK+w/t0l7duxXbMu5ETS1/hPkI6TVUnvrS2PgxmkLhYjJB1J6i4AKYfeS/rgfXDOr9+pcNsrk46/nauwH9NIxfQxkg7LMfyT9MGxPeXywOO5fTjp/eMeUi5fhcX5s63XUVs5qLS90cUr87SxXx/k5QeRvuk+G1i+neXuyH+/nf8nh5Tb53w1i8+1sy7roEZdB/kKlj5bexqp3+AppBdzZ9xN+vpiJ9LZsEsjYgHpzWYm6evKk0nFzKwK1/lV0ovmBNIPsS4Evt/eQhHxKulF9g/gx6QX3dcj4vZKNhoRdwAHk76+v5jUP+vuChZ9Py/3C9IL/2LSWcmW63+X1J9SwOT8YQDSi/g80tc9F5GK4j9J6kv6sUfLXxKXi71T+16t9TTbc1hm+X/m+fqQzj5vlyfdldd5T0S8RUr6pfb29qutbV9F6uP3TdLZ1PdI3TLOJx3Td5POhlfLn0k/DtqO9COitduZ/2jgl8C+Ob6tKf+8P0v6Icon8t9NW1nft0kfQk4tt54OOpr0pvtN0vNXvJrLSaRi5UTSWbails/9NNK3aluQuoLcUpj3XdLZuZ+TnotrgesiYgIpDw0mfaswisVv+lNI/ZH/k/ScWPdW+o3E5aTXwakR8Q9aHAc5x4wgdb36PqlQO5XULeFlFneBOJZ0XMPis8BLiIinSbliAKlrRCUnS9oUETNIHyYXsvi3H/vm9vaWXSoPROpn8Bdy/iSdsX09L1LKn229jo6m9Rx0Kem96DTa+ZYtIv5GKo7fzuv5NumDSpsnZyLir6T/xb+QTrzclSeV9uEC0lnviyl/0sWqoPQLVrOKSPoq8NWIGN7oWMzMrPNyXn+NVFCeTuqK8NlcqFkD5G8wnyOdADmPdBWiwRHxUkMD60Ea0QfZurCI+DVL9rE1M7OubXPSmcgVSZduHOXiuOG2JRXGkL49/JqL4/ryGWQzMzMzs4JG9UE2MzMzM2tKLpDNzMzMzApcIJuZmZmZFbhANjMzMzMrcIFsZtbNSBovaZ6kx1u0HynpaUlPSPpBof1ESTMlzZC0W6F9eG6bmW+SVGofJOm+3H6tpBXqs2dmZvXhAtnMrPu5gnQXsUUk7UC6WcSnI2Iz0q2tybdPH0m6AdBw4GeSeknqRboRwe6kW4+PKtxq/Vzg/IjYmHyXy5rvkZlZHblANjPrZiLiTmBBi+b/As6JiPfzPPNy+whgYkS8HxHPke42ulV+zIyIZyPiA9Id/0ZIErAjcF1efgLVu4W3mVlT6JY3CllnnXVi4MCBy7zcCw+2vPt1/az/2fXbnN7I2KC542svNrNm8eCDD74SEX0btPlPANtJOot0e+xjI+IBoD9wb2G+ObkN0i2zi+1bk24V/npELCwz/xIkjSXdAp1VV131s5tu2trdwM3MGqO1vNwtC+SBAwcyffr0ZV7udJ1eg2gqM276uDanNzI2aO742ovNrFlIer6Bm+8NrAUMAz4HTJL0r7XcYERcBlwGMHTo0OhIXjYzq6XW8nK3LJDNzGwpc4AbIt0+9X5JHwHrAHOBDQrzDchttNL+KtBHUu98Frk4v5lZt+A+yGZmPcPvgB0AJH0CWAF4BZgCjJS0oqRBwGDgfuABYHC+YsUKpB/yTckF9u3APnm9o4HJ9dwRM7Na8xlkM7NuRtI1wPbAOpLmAOOA8cD4fOm3D4DRudh9QtIk4ElgIXB4RHyY13MEcAvQCxgfEU/kTRwPTJT0PeBh4PK67ZyZWR24QDYz62YiYlQrk77ayvxnAWeVaZ8KTC3T/izpKhdmZt2Su1iYmZmZmRW4QDYzMzMzK3CBbGZmZmZW4ALZzMzMzKzAP9IzMzOrt6tVm/XuH7VZr1kP4wLZzMysO3MxbrbM3MXCzMzMzKzABbKZmZmZWYELZDMzMzOzAhfIZmZmZmYFLpDNzMzMzApcIJuZmZmZFbhANjMzMzMrcIFsZmZmZlbgAtnMzMzMrMAFspmZmZlZgQtkMzMzM7MCF8hmZmZmZgUukM3MuhlJ4yXNk/R4mWnHSApJ6+RxSbpQ0kxJj0rasjDvaEnP5MfoQvtnJT2Wl7lQkuqzZ2Zm9VGzAlnSBpJul/SkpCckHZXb15I0LSfcaZLWzO3LnKTNzKysK4DhLRslbQDsCvyj0Lw7MDg/xgKX5HnXAsYBWwNbAeNK+TrPc1hhuaW2ZWbWldXyDPJC4JiIGAIMAw6XNAQ4AbgtIgYDt+Vx6FiSNjOzFiLiTmBBmUnnA/8NRKFtBHBlJPcCfSStB+wGTIuIBRHxGjANGJ6nrR4R90ZEAFcCe9dwd8zM6q5mBXJEvBgRD+Xht4CngP6kZDwhzzaBxYl1mZJ0reI2M+uOJI0A5kbEX1tM6g/MLozPyW1ttc8p015um2MlTZc0ff78+Z3cAzOz+qlLH2RJA4HPAPcB/SLixTzpJaBfHl7WJN1yG07EZmZlSFoFOAk4tZ7bjYjLImJoRAzt27dvPTdtZtYpNS+QJX0MuB44OiLeLE7LX89F2QWXkROxmVmrPg4MAv4qaRYwAHhI0r8Ac4ENCvMOyG1ttQ8o025m1m3UtECWtDypOL4qIm7IzS/nrhPkv/Ny+7ImaTMzq0BEPBYR60bEwIgYSPombsuIeAmYAhyUfyg9DHgjf8t3C7CrpDXz7z52BW7J096UNCxfveIgYHJDdszMrEZqeRULAZcDT0XEjwuTpgClK1GMZnFiXaYkXau4zcy6OknXAPcAm0iaI+nQNmafCjwLzAR+AXwTICIWAGcCD+THGbmNPM8v8zJ/B26qxX6YmTVK7xque1vgQOAxSY/ktpOAc4BJOWE/D+ybp00F9iAl3HeBgyElaUmlJA1LJmkzM2shIka1M31gYTiAw1uZbzwwvkz7dGDzzkVpZta8alYgR8SfgdYuHr9TmfmXOUmbmZmZmVWb76RnZmZmZlbgAtnMzMzMrMAFspmZmZlZgQtkMzMzM7MCF8hmZmZmZgUukM3MzMzMClwgm5mZmZkVuEA2MzMzMytwgWxmZmZmVuAC2czMzMyswAWymZmZmVmBC2QzMzMzswIXyGZmZmZmBS6QzczMzMwKXCCbmZmZmRW4QDYzMzMzK3CBbGZmZmZW4ALZzKybkTRe0jxJjxfazpP0tKRHJf1WUp/CtBMlzZQ0Q9JuhfbhuW2mpBMK7YMk3Zfbr5W0Qt12zsysDlwgm5l1P1cAw1u0TQM2j4hPAX8DTgSQNAQYCWyWl/mZpF6SegEXA7sDQ4BReV6Ac4HzI2Jj4DXg0NrujplZfblANjPrZiLiTmBBi7ZbI2JhHr0XGJCHRwATI+L9iHgOmAlslR8zI+LZiPgAmAiMkCRgR+C6vPwEYO9a7o+ZWb25QDYz63kOAW7Kw/2B2YVpc3Jba+1rA68Xiu1Su5lZt+EC2cysB5F0MrAQuKoO2xorabqk6fPnz6/15szMqsYFsplZDyFpDLAncEBERG6eC2xQmG1Abmut/VWgj6TeLdqXEhGXRcTQiBjat2/fqu2HmVmtuUA2M+sBJA0H/hvYKyLeLUyaAoyUtKKkQcBg4H7gAWBwvmLFCqQf8k3JhfXtwD55+dHA5Hrth5lZPbhANjPrZiRdA9wDbCJpjqRDgYuA1YBpkh6R9HOAiHgCmAQ8CdwMHB4RH+Y+xkcAtwBPAZPyvADHA9+RNJPUJ/nyOu6emVnN9W5/FjMz60oiYlSZ5laL2Ig4CzirTPtUYGqZ9mdJV7kwM+uWfAbZzMzMzKzABbKZmZmZWYELZDMzMzOzAhfIZmZmZmYFLpDNzMzMzApcIJuZmZmZFbRbIEv6iqTV8vB3Jd0gacvah2Zm1rM5/5qZNUYlZ5BPiYi3JH0e2Jl0Lc1LahuWmZnh/Gtm1hCVFMgf5r9fBC6LiN8DK9QuJDMzy5x/zcwaoJICea6kS4H9gKmSVqxwOTMz6xznXzOzBqgk0e4L3ALsFhGvA2sBx9UyKDMzA5x/zcwaopIC+dKIuCEingGIiBeBA2sblpmZ4fxrZtYQlRTImxVHJPUCPtveQpLGS5on6fFC22mS5kp6JD/2KEw7UdJMSTMk7VZoH57bZko6obLdMjPrFjqUf83MrHNaLZBzwfoW8ClJb0p6K4/PAyZXsO4rgOFl2s+PiC3yY2re1hBgJOnNYDjwM0m98pvBxcDuwBBgVJ7XzKzbqkL+NTOzTmi1QI6IsyNiNeC8iFg9IlbLj7Uj4sT2VhwRdwILKoxjBDAxIt6PiOeAmcBW+TEzIp6NiA+AiXleM7Nuq7P518zMOqeSLhYnS/qqpFMAJG0gaatObPMISY/mLhhr5rb+wOzCPHNyW2vtS5E0VtJ0SdPnz5/fifDMzJpGtfOvmZlVoJIC+WJgG2D/PP52buuIS4CPA1sALwI/6uB6lhIRl0XE0IgY2rdv32qt1syskaqZf83MrEK9K5hn64jYUtLDABHxmqQOXag+Il4uDUv6BXBjHp0LbFCYdUBuo412M7Purmr518zMKlfJGeR/5h/LBYCkvsBHHdmYpPUKo18CSle4mAKMlLSipEHAYOB+4AFgsKRB+U1hZJ7XzKwn6FD+beUqQmtJmibpmfx3zdwuSRfmKwU9KmnLwjKj8/zPSBpdaP+spMfyMhdKUjV32sys0SopkC8Efgv0k3QW8Gfg++0tJOka4B5gE0lzJB0K/CAn1UeBHYBvA0TEE8Ak4EngZuDwiPgwIhYCR5AulP8UMCnPa2bWE3Qo/1L+KkInALdFxGDgtjwO6SpBg/NjLKkrHJLWAsYBW5N+MD2u8LuRS4DDCsuVu2KRmVmX1W4Xi4i4StKDwE6AgL0j4qkKlhtVpvnyNuY/CzirTPtUYGp72zMz6246kX/vlDSwRfMIYPs8PAG4Azg+t18ZEQHcK6lP/rZve2BaRCwAkDQNGC7pDmD1iLg3t18J7A3c1OEdNTNrMpWcQQZYB3g3Ii4CXsndIMzMrPaqlX/75TvxAbwE9MvDy3oVof55uGW7mVm30W6BLGkc6SxD6dqbywO/rmVQZmZWu/ybzxZHZ9fTHl9+08y6qkrOIH8J2At4ByAiXgBWq2VQZmYGVDf/vlz6oXT+Oy+3t3YVobbaB5RpX4ovv2lmXVUlBfIHxbMNklatbUhmZpZVM/9OAUpXohjN4ltWTwEOylezGAa8kbti3ALsKmnN/OO8XYFb8rQ3JQ3LV684CN/+2sy6mUqugzxJ0qVAH0mHAYcAv6htWGZmRgfzb76K0PbAOpLmkK5GcU5e36HA88C+efapwB7ATOBd4GCAiFgg6UzS5TYBzij9YA/4JulKGSuTfpznH+iZWbdSyVUsfihpF+BNYBPg1IiYVvPIzMx6uI7m31auIgTpahgt5w3g8FbWMx4YX6Z9OrB5e3GYmXVV7RbI+WzDnRFxXB3iMTOzzPnXzKwxKulisSFwab6m5oPAncBdEfFIDeMyMzPnXzOzhmj3R3oRMS4idgQ2A+4CjiMlajMzqyHnXzOzxqiki8V3gW2BjwEPA8eSErWZmdWQ86+ZWWNU0sXiy8BC4PfAn4B7IuL9mkZlZmbg/Gtm1hCVXMViS0mrk85i7AJcJmleRHy+5tGZmfVgzr91drVqs979a37TQjOrskq6WGwObAf8OzAUmI2/4jMzqznnXzOzxqiki8U5pF9OXwg8EBH/rG1IZmaWOf+amTVAJbea/kNE/CAi7i4lZ0lH1TguMzNz/jUza4hKCuSDyrSNqXIcZma2NOdfM7MGaLWLhaRRwP7AIElTCpNWAxbUOjAzs57K+dfMrLHa6oN8N/AisA7wo0L7W8CjtQzKzKyHc/41M2ugVgvkiHgeeB7Ypn7hmJmZ86+ZWWNV0gfZzMzMzKzHcIFsZmZmZlbQaoEs6bb899z6hWNmZs6/ZmaN1daP9NaT9G/AXpImAkvcgzMiHqppZGZmPZfzr5lZA7VVIJ8KnAIMAH7cYloAO9YqKDOzHs7518ysgdq6isV1wHWSTomIM+sYk5lZj1bL/Cvp28DXSIX2Y8DBwHrARGBt4EHgwIj4QNKKwJXAZ4FXgf0iYlZez4nAocCHwLci4pZqxmlm1kjt/kgvIs6UtJekH+bHnvUIzMysp6t2/pXUH/gWMDQiNgd6ASOBc4HzI2Jj4DVS4Uv++1puPz/Ph6QhebnNgOHAzyT16kxsZmbNpN0CWdLZwFHAk/lxlKTv1zowM7Oerkb5tzewsqTewCqkG5LsCFyXp08A9s7DI/I4efpOkpTbJ0bE+xHxHDAT2KqTcZmZNY22+iCXfBHYIiI+ApA0AXgYOKmWgZmZWXXzb0TMlfRD4B/A/wG3krpUvB4RC/Nsc4D+ebg/MDsvu1DSG6RuGP2BewurLi5jZtblVXod5D6F4TVqEIeZmZXXpzDcqfwraU3S2d9BwPrAqqQuEjUhaayk6ZKmz58/v1abMTOrukrOIJ8NPCzpdtKlhr4AnFDTqMzMDKqff3cGnouI+QCSbgC2BfpI6p3PIg8A5ub55wIbAHNyl4w1SD/WK7WXFJdZJCIuAy4DGDp0aHQibjOzuqrkR3rXAMOAG4DrgW0i4tpaB2Zm1tPVIP/+AxgmaZXcl3gnUt/m24F98jyjgcl5eEoeJ0//Y0REbh8paUVJg4DBwP2diMvMrKlUcgaZiHiRlBDNzKyOqpl/I+I+SdcBDwELSf2ZLwN+D0yU9L3cdnle5HLgfyTNBBaQrlxBRDwhaRKpuF4IHB4RH1YjRjOzZlBRgWxmZt1DRIwDxrVofpYyV6GIiPeAr7SynrOAs6oeoJlZE6j0R3pmZmZmZj1CmwWypF6Snq5XMGZmljj/mpk1TpsFcu5TNkPShnWKx8zMcP41M2ukSvogrwk8Iel+4J1SY0TsVbOozMwMnH/NzBqikgL5lJpHYWZm5Tj/mpk1QCXXQf4TMAtYPg8/QLpEUJskjZc0T9Ljhba1JE2T9Ez+u2Zul6QLJc2U9KikLQvLjM7zPyNpdLltmZl1Rx3Nv2Zm1jntFsiSDgOuAy7NTf2B31Ww7itY+hamJwC3RcRg4DYW3xFqd9KF5gcDY4FL8rbXIl2OaGvSJYjGlYpqM7PurhP518zMOqGSy7wdTroV6ZsAEfEMsG57C0XEnaQLyxeNACbk4QnA3oX2KyO5l3Tb0/WA3YBpEbEgIl4DprF00W1m1l11KP+amVnnVFIgvx8RH5RGJPUGooPb65fvCgXwEtAvD/cHZhfmm5PbWmtfiqSxkqZLmj5//vwOhmdm1lSqmX/NzKxClRTIf5J0ErCypF2A3wD/29kNR0RQxUQfEZdFxNCIGNq3b99qrdbMrJFqkn/NzKxtlRTIJwDzgceArwNTge92cHsv564T5L/zcvtcYIPCfANyW2vtZmY9QTXzr5mZVajdy7xFxEeSJgD3kc74zshnfztiCjAaOCf/nVxoP0LSRNIP8t6IiBcl3QJ8v/DDvF2BEzu4bTOzLqXK+dfMzCrUboEs6YvAz4G/AwIGSfp6RNzUznLXANsD60iaQ7oaxTnAJEmHAs8D++bZpwJ7ADOBd4GDASJigaQzSZc2AjgjIlr+8M/MrFvqaP41M7POqeRGIT8CdoiImQCSPg78HmgzQUfEqFYm7VRm3iD9WrvcesYD4yuI08ysu+lQ/jUzs86ppA/yW6XknD0LvFWjeMzMbDHnXzOzBmj1DLKkL+fB6ZKmApNIfeC+wuIuD2ZmVmXOv2ZmjdVWF4v/KAy/DPx7Hp4PrFyziMzMzPnXzKyBWi2QI+LgegZiZmaJ86+ZWWNVchWLQcCRwMDi/BGxV+3CMquPGTNmsN9++y0af/bZZznjjDO45557mDFjBgCvv/46ffr04ZFHHgHg7LPP5vLLL6dXr15ceOGF7Lbbbo0I3XqAWuRfSX2AXwKbk7ptHALMAK7N25kF7BsRr0kScAHpKkPvAmMi4qG8ntEsvibz9yJiQkdjMjNrNpVcxeJ3wOWkuzd9VNNozOpsk002WVT4fvjhh/Tv358vfelLHH300YvmOeaYY1hjjTUAePLJJ5k4cSJPPPEEL7zwAjvvvDN/+9vf6NWrVwOitx7gd1Q//14A3BwR+0haAVgFOAm4LSLOkXQC6QYlxwO7A4PzY2vgEmBrSWuRLt05lFRkPyhpSkS8VqUYzcwaqpIC+b2IuLDmkZg12G233cbHP/5xNtpoo0VtEcGkSZP44x//CMDkyZMZOXIkK664IoMGDWLjjTfm/vvvZ5tttmlU2Na9VTX/SloD+AIwBiAiPgA+kDSCdN16gAnAHaQCeQRwZb4U572S+uS7oG4PTCtdl17SNGA4cE21YjUza6RKCuQLJI0DbgXeLzWWvmYz6y4mTpzIqFFLXr77rrvuol+/fgwePBiAuXPnMmzYsEXTBwwYwNy5vvu51Uy18+8g0g/9fiXp08CDwFFAv4h4Mc/zEtAvD/cHZheWn5PbWms3M+sWKimQPwkcCOzI4q/4Io+bdQsffPABU6ZM4eyzz16i/ZprrlmqaDaro2rn397AlsCREXGfpAtI3SkWiYiQVJXbWUsaC4wF2HDDDauxSjOzuqikQP4K8K/5qzizbummm25iyy23pF+/fovaFi5cyA033MCDDz64qK1///7Mnr34xNmcOXPo398nzqxmqp1/5wBzIuK+PH4dqUB+WdJ6EfFi7kIxL0+fC2xQWH5AbpvL4i4ZpfY7Wm4sIi4DLgMYOnRoVYpuM7N6qOROeo8DfWoch1lDlTtT/Ic//IFNN92UAQMGLGrba6+9mDhxIu+//z7PPfcczzzzDFtttVW9w7Weo6r5NyJeAmZL2iQ37QQ8CUwBRue20cDkPDwFOEjJMOCN3BXjFmBXSWtKWhPYNbeZmXULlZxB7gM8LekBluwD58u8WbfwzjvvMG3aNC699NIl2sv1Sd5ss83Yd999GTJkCL179+biiy/2FSyslvpQ/fx7JHBVvoLFs8DBpJMlkyQdCjwP7JvnnUq6xNtM0mXeDs7bXyDpTBbf1e+M0g/2zMy6g0oK5HE1j8KsgVZddVVeffXVpdqvuOKKsvOffPLJnHzyyTWOygyoQf6NiEdIl2draacy8wZweCvrGQ+Mr2pwZmZNot0COSL+VI9AzMxsSc6/ZmaNUcmd9N4i/WoaYAVgeeCdiFi9loGZmfV0zr9mZo1RyRnk1UrD+bajI4BhrS9hZmbV4PxrZtYYlfRBXiT3R/tdvnD9Ce3Nb9YMTtfpDdv2uHAXfqsO518zs/qppIvFlwujy5F+3PFezSIyMzPA+dfMrFEqOYP8H4XhhcAs0td8ZmZWW86/ZmYNUEkf5IPrEYiZmS3J+dfMrDFaLZAlndrGchERZ9YgHjOzHs/518yssdo6g/xOmbZVgUOBtQEnaDOz2nD+NTNroFYL5Ij4UWlY0mrAUaTbjE4EftTacmZm1jnOv2ZmjdVmH2RJawHfAQ4AJgBbRsRr9QjMzKwnc/41M2uctvognwd8GbgM+GREvF23qMzMejDnXzOzxlqujWnHAOsD3wVekPRmfrwl6c36hGdm1iM5/5qZNVBbfZDbKp7NzKxGnH/NzBrLSdjMzMzMrMAFspmZmZlZgQtkMzMzM7MCF8hmZmZmZgUukM3MehhJvSQ9LOnGPD5I0n2SZkq6VtIKuX3FPD4zTx9YWMeJuX2GpN0atCtmZjXhAtnMrOc5CniqMH4ucH5EbAy8RrqlNfnva7n9/DwfkoYAI4HNgOHAzyT1qlPsZmY15wLZzKwHkTQA+CLwyzwuYEfgujzLBGDvPDwij5On75TnHwFMjIj3I+I5YCawVV12wMysDlwgm5n1LD8B/hv4KI+vDbweEQvz+Bygfx7uD8wGyNPfyPMvai+zjJlZl+cC2cysh5C0JzAvIh6s0/bGSpouafr8+fPrsUkzs6pwgWxm1nNsC+wlaRYwkdS14gKgj6TSnVUHAHPz8FxgA4A8fQ3g1WJ7mWUWiYjLImJoRAzt27dv9ffGzKxGXCCbmfUQEXFiRAyIiIGkH9n9MSIOAG4H9smzjQYm5+EpeZw8/Y8REbl9ZL7KxSBgMHB/nXbDzKzmerc/S/XlsxdvAR8CCyNiqKS1gGuBgcAsYN+IeC3/IOQCYA/gXWBMRDzUiLjNzLqp44GJkr4HPAxcntsvB/5H0kxgAamoJiKekDQJeBJYCBweER/WP2xrSlerNuvdP2qzXrMyGlIgZztExCuF8ROA2yLiHEkn5PHjgd1JZycGA1sDl+S/ZmbWQRFxB3BHHn6WMlehiIj3gK+0svxZwFm1i9DMrHGaqYtF8XJCLS8zdGUk95L6yq3XgPjMzMzMrAdoVIEcwK2SHpQ0Nrf1i4gX8/BLQL887MsJmZmZmVndNKqLxecjYq6kdYFpkp4uToyIkLRMnY1yoT0WYMMNN6xepGZm1ji16M/qvqxm1o6GnEGOiLn57zzgt6S+by+Xuk7kv/Py7L6ckJmZmZnVTd0LZEmrSlqtNAzsCjzOkpcTanmZoYOUDAPeKHTFMDMzMzOrqkZ0segH/DZdvY3ewNURcbOkB4BJkg4Fngf2zfNPJV3ibSbpMm8H1z9kMzMzM+sp6l4g58sJfbpM+6vATmXaAzi8DqGZmZmZmTXVZd7MzMzMzBrOBbKZmZmZWYELZDMzMzOzAhfIZmZmZmYFLpDNzMzMzApcIJuZmZmZFbhANjMzMzMrcIFsZmZmZlbgAtnMzMzMrMAFspmZmZlZgQtkMzMzM7MCF8hmZmZmZgUukM3MeghJG0i6XdKTkp6QdFRuX0vSNEnP5L9r5nZJulDSTEmPStqysK7Ref5nJI1u1D6ZmdWCC2Qzs55jIXBMRAwBhgGHSxoCnADcFhGDgdvyOMDuwOD8GAtcAqmgBsYBWwNbAeNKRbWZWXfgAtnMrIeIiBcj4qE8/BbwFNAfGAFMyLNNAPbOwyOAKyO5F+gjaT1gN2BaRCyIiNeAacDw+u2JmVltuUA2M+uBJA0EPgPcB/SLiBfzpJeAfnm4PzC7sNic3NZae8ttjJU0XdL0+fPnV3cHzMxqyAWymVkPI+ljwPXA0RHxZnFaRAQQ1dhORFwWEUMjYmjfvn2rsUozs7pwgWxm1oNIWp5UHF8VETfk5pdz1wny33m5fS6wQWHxAbmttXYzs27BBbKZWQ8hScDlwFMR8ePCpClA6UoUo4HJhfaD8tUshgFv5K4YtwC7Sloz/zhv19xmZtYt9G50AGZmVjfbAgcCj0l6JLedBJwDTJJ0KPA8sG+eNhXYA5gJvAscDBARCySdCTyQ5zsjIhbUZQ/MzOrABbKZWQ8REX8G1MrkncrMH8DhraxrPDC+etGZmTUPd7EwMzMzMytwgWxmZmZmVuAC2czMzMyswAWymZmZmVmBC2QzMzMzswIXyGZmZmZmBS6QzczMzMwKfB1ksy7ikEMO4cYbb2Tdddfl8ccfB+CUU05h8uTJLLfccqy77rpcccUVrL/++g2O1MysTq5u7bLenbR/1Ga91mX4DLJZFzFmzBhuvvnmJdqOO+44Hn30UR555BH23HNPzjjjjAZF13UccsghrLvuumy++eaNDsXMzJqUzyCbdRFf+MIXmDVr1hJtq6+++qLhd955B6lGZ1O6kTFjxnDEEUdw0EEHNToUM+tK6n222mfHG8oFslkXd/LJJ3PllVeyxhprcPvttzc6nKZX7oOGmZlZkbtYmHVxZ511FrNnz+aAAw7goosuanQ4ZmZmXZ4LZLNu4oADDuD6669vdBhmZmZdngtksy7smWeeWTQ8efJkNt100wZGY2Zm1j24D7JZFzFq1CjuuOMOXnnlFQYMGMDpp5/O1KlTmTFjBssttxwbbbQRP//5zxsdppmZWZfnAtmsi7jmmmuWajv00EMbEEnXVu6Dhp9HMzMrcoFsZj1KuQ8aZmY9mi8ptxT3QTYzMzMzK+gyBbKk4ZJmSJop6YRGx2Nm1tM5L5tZd9UlCmRJvYCLgd2BIcAoSUMaG5WZWc/lvGxm3VlX6YO8FTAzIp4FkDQRGAE82dCozDrpdJ3e0O2Pi3EN3b51ac7LZrbsukh/Z0U0fwdqSfsAwyPia3n8QGDriDiiMM9YYGwe3QSYUfdAYR3glQZstxKOreOaOT7H1nGNiG+jiOhb523WRBXzcrMfJ63pinF3xZiha8bdFWOGrhl3Z2Mum5e7yhnkdkXEZcBljYxB0vSIGNrIGFrj2DqumeNzbB3X7PF1B5Xk5a76f+iKcXfFmKFrxt0VY4auGXetYu4SfZCBucAGhfEBuc3MzBrDednMuq2uUiA/AAyWNEjSCsBIYEqDYzIz68mcl82s2+oSXSwiYqGkI4BbgF7A+Ih4osFhldPQLh7tcGwd18zxObaOa/b4mloV83JX/T90xbi7YszQNePuijFD14y7JjF3iR/pmZmZmZnVS1fpYmFmZmZmVhcukM3MzMzMClwgV0Ez325V0nhJ8yQ93uhYWpK0gaTbJT0p6QlJRzU6phJJK0m6X9Jfc2yNvaNHGZJ6SXpY0o2NjqUlSbMkPSbpEUnTGx1PkaQ+kq6T9LSkpyRt0+iYeqpmzp1F5fKopLUkTZP0TP67ZiNjbKm1/NrMcbeWd/MPQe/Lx8m1+UehTadlTm72uMvl6WY+PkrK5fBaxO0CuZO6wO1WrwCGNzqIViwEjomIIcAw4PAmeu7eB3aMiE8DWwDDJQ1rbEhLOQp4qtFBtGGHiNiiCa+peQFwc0RsCnya5n4Ou60ukDuLrmDpPHoCcFtEDAZuy+PNpLX82sxxt5Z3zwXOj4iNgdeAQxsXYpta5uSuEHfLPN3Mx0dJuRxe9bhdIHfeotutRsQHQOl2q00hIu4EFjQ6jnIi4sWIeCgPv0U6yPs3Nqokkrfz6PL50TS/aJU0APgi8MtGx9KVSFoD+AJwOUBEfBARrzc0qJ6rqXNnUSt5dAQwIQ9PAPauZ0ztaSO/Nm3cbeTdHYHrcntTxVzSMidLEl0g7jKa9viANnN41eN2gdx5/YHZhfE5NEmR15VIGgh8BrivwaEskr8uewSYB0yLiKaJDfgJ8N/ARw2OozUB3CrpQaXbDTeLQcB84Ff5q9BfSlq10UH1UF09d/aLiBfz8EtAv0YG05YW+bWp426Zd4G/A69HxMI8S7MeJz9hyZy8Ns0fd7k83dTHB63n8KrH7QLZGk7Sx4DrgaMj4s1Gx1MSER9GxBakO4RtJWnzBocEgKQ9gXkR8WCjY2nD5yNiS9LX54dL+kKjA8p6A1sCl0TEZ4B3aM6vEK0LiXS91Kb5hqmorfzajHG3zLvApo2NqH1dJCeX02aebsbjgwpyeLXidoHceb7daidIWp6UvK+KiBsaHU85+eub22mevtzbAntJmkX6WnpHSb9ubEhLioi5+e884LekN7pmMAeYU/g24DpSsrX66+q582VJ6wHkv/MaHM9SWsmvTR83LJF3twH6SCrd2KwZj5OlcjKpn2xTx91Knm7246O1HF71uF0gd55vt9pBuY/W5cBTEfHjRsdTJKmvpD55eGVgF+DphgaVRcSJETEgIgaSjrc/RsRXGxzWIpJWlbRaaRjYFWiKq6hExEvAbEmb5KadgCcbGFJP1tVz5xRgdB4eDUxuYCxLaSO/Nm3creTdp0iF8j55tqaKGVrNyQfQxHG3kaeb9viANnN41ePuEreabmbNfhtsSdcA2wPrSJoDjIuIyxsb1SLbAgcCj+U+ZwAnRcTUxoW0yHrAhPxL++WASRHRdJdTa1L9gN+m92d6A1dHxM2NDWkJRwJX5aLsWeDgBsfTIzV77iwql0eBc4BJkg4Fngf2bVyEZZXNrzR33GXzrqQngYmSvgc8TP6BVhdwPM0bd9k8LekBmvf4KCmXw5ejynH7VtNmZmZmZgXuYmFmZmZmVuAC2czMzMyswAWymZmZmVmBC2QzMzMzswIXyGZmZmZmBS6QrcuRtLakR/LjJUlzC+MrVGkbW0jao5Vp20tq85JvksZIumgZtzlL0jrLsoyZWSMtSz7uijlO0t6ShjQ6Dqs/XwfZupyIeBXYAkDSacDbEfHDKm9mC2Ao0AzXZDYza0p1yseNtDdwI76hUI/jM8jWHSwn6UEASZ+WFJI2zON/l7RKvkPT9ZIeyI9t8/RVJY2XdL+khyWNyGc9zgD2y2dB9mttw5K2knRPXvbuwt19ADaQdIekZySNKyzz1by9RyRdmi+Kb2bWLUjaKefEx3J+XbHF9JUl3STpsHI5OM8zRtINkm7OOfQHrWzrczn3/jWvYzVJK0n6Vd7+w5J2KKzzosKyN0raPg+/LemsvJ57JfWT9G/AXsB5OV9/vDbPmDUjF8jWHXwErCRpdWA7YDqwnaSNgHkR8S5wAXB+RHwO+E/gl3nZk0m3Bd0K2AE4D1geOBW4NiK2iIhr29j208B2EfGZvMz3C9O2ytv6FPAVSUMl/T9gP2DbiNgC+BA4oNPPgJlZc1gJuALYLyI+Sfqm+r8K0z8G/C9wTUT8gjI5WOnWx5DOTO8HfJJ0wmKD4obyyYxrgaMi4tPAzsD/AYcDkbc/inR3vpXaiXtV4N68njuBwyLibtItjI/L7wV/X+Znw7osd7Gw7uJu0q1Vv0AqUocDAu7K03cGhuTbagKsLuljpPvP7yXp2Ny+ErDhMmx3DVLyHQwEqbgumZa/fkTSDcDngYXAZ4EHciwrA/OWYXtmZs2sF/BcRPwtj08gFaw/yeOTgR9ExFV5vK0cfFtEvAGgdLvpjYDZhW1tArwYEQ8ARMSbed7PAz/NbU9Leh74RDtxf0DqSgHwILBLpTts3ZMLZOsu7iSdPd6IlICPJxWsv8/TlwOGRcR7xYWUqtT/jIgZLdq3rnC7ZwK3R8SXJA0E7ihMa3kf9yAV7RMi4sQK129m1p38BRgu6eqIKOXE1nLw+4WmD+l8zbKQJb85L55V/meOp1rbsi7OXSysu7gL+CrwTER8BCwA9gD+nKffChxZmlnSFnnwFuDIXCgj6TO5/S1gtQq2uwYwNw+PaTFtF0lrSVqZ9EOPvwC3AftIWjdvb63cFcTMrDv4EBgoaeM8fiDwp8L0U4HXgIvzeGs5uBIzgPUkfS4vu5qk3qT3gwNy2ydIZ6RnALOALSQtl7trbFXBNip9L7BuxgWydQsRMYt0JuLO3PRn4PWIeC2PfwsYKunR/FXdN3L7maRuEY9KeiKPA9xO6pLR5o/0gB8AZ0t6mKXPONwPXA88ClwfEdMj4kngu8Ctkh4FpgHrdWinzcyaz3vAwcBvJD1G+o3Iz1vMcxSwcv7hXWs5uF0R8QGpj/JPJf2VlE9XAn5G+vH2Y6Q+ymMi4n3SSYrnSFekuBB4qILNTASOyz/284/0ehAt/kbBzMzMzMx8BtnMzMzMrMAFspmZmZlZgQtkMzMzM7MCF8hmZmZmZgUukM3MzMzMClwgm5mZmZkVuEA2MzMzMyv4///r44NBTBVqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Distribution by class\n",
    "ax[0].bar(x = df['hate_speech'].unique(), # Data labels\n",
    "       height = df['hate_speech'].value_counts().values, # Num of tweets in each category\n",
    "       color='purple')\n",
    "\n",
    "ax[0].bar_label(ax[0].containers[0], label_type='edge', padding=3) # Annotate bars\n",
    "ax[0].set_ylim(0, 2300) # Raise upper limit of y-axis, to accommodate labels\n",
    "\n",
    "ax[0].set_title(\"Number of offensive/non-offensive tweets in the train dataset\", \n",
    "             fontweight='bold', fontsize=10, y = 1.02)\n",
    "ax[0].set_ylabel(\"Number of tweets\")\n",
    "ax[0].set_xlabel('Tweet label')\n",
    "\n",
    "# Distribution by length\n",
    "ax[1].hist([len(tweet) for tweet in df['tweet'].apply(lambda x: x.split())], \n",
    "           color='orange', rwidth=0.8)\n",
    "ax[1].set_xlabel('Token count')\n",
    "ax[1].set_ylabel('Number of tweets')\n",
    "ax[1].set_title(\"Histogram of tweet length\", \n",
    "                fontweight='bold', fontsize=10, y = 1.02)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8xQTJpcZYM3"
   },
   "source": [
    "#### Deal with class imbalances\n",
    "\n",
    "Downsample from the majority ('Non-Offensive') class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wLUU1XIZkir",
    "outputId": "a6dc7765-4312-4a35-8ec4-88565e3241fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before downsampling: \n",
      "Offensive: 7483\n",
      "Neither: 39448\n",
      "\n",
      "After downsampling: \n",
      "Offensive: 7483\n",
      "Neither: 7483\n"
     ]
    }
   ],
   "source": [
    "print('Before downsampling: ')\n",
    "print(f\"Offensive: {len(df[df['hate_speech']==1])}\")\n",
    "print(f\"Neither: {len(df[df['hate_speech']==0])}\")\n",
    "\n",
    "train_hateful = df[df['hate_speech']==1]\n",
    "train_nonhateful = df[df['hate_speech']==0].sample(len(train_hateful))\n",
    "train_downsampled = pd.concat([train_hateful, train_nonhateful], axis=0).sample(frac=1)\n",
    "\n",
    "print('\\nAfter downsampling: ')\n",
    "print(f\"Offensive: {len(train_downsampled[train_downsampled['hate_speech']==1])}\")\n",
    "print(f\"Neither: {len(train_downsampled[train_downsampled['hate_speech']==0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA_8-IV2cgMK"
   },
   "source": [
    "#### Split train data set into train and development sets\n",
    "\n",
    "To provide a way to assess the model's performance after each training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mbSzTpTxclIR"
   },
   "outputs": [],
   "source": [
    "# Split train data set into train and development sets\n",
    "train, dev = train_test_split(train_downsampled, test_size=0.5, stratify=train_downsampled['hate_speech'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bl1muGb6dNg3"
   },
   "source": [
    "Prepare data\n",
    "\n",
    "Convert the text and labels into a format that is acceptable for the model. First, torch.utils.data.Dataset - stores the samples and their corresponding labels. We create a simple pipeline for cleaning and tokenizing the tweets. I will use the bert-base-uncased tokenizer so that the tokenizer matches the model. This is because (1) the model has a specific, fixed vocabulary, and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words.torch.utils.data.DataLoader - wraps an iterable around the Dataset, enabling us to iterate through the samples. Can also be used to transform the data (if you provide a custom collate_fn).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QwuHykh-dnBA"
   },
   "outputs": [],
   "source": [
    "# Clean the tweets' text\n",
    "def clean_text(tweet):\n",
    "    \"\"\"A function that performs basic cleaning of a tweet's text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace mentions and URLs with special token\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9_-]+\",'USR',tweet)\n",
    "    tweet = re.sub(r\"http\\S+\",'URL',tweet)\n",
    "    \n",
    "    # Remove \\n and \\t characters\n",
    "    tweet = tweet.replace('\\n', ' ')\n",
    "    tweet = tweet.replace('[NEWLINE]', ' ')\n",
    "    tweet = tweet.replace('\\t', ' ')\n",
    "    \n",
    "    # Strip whitespace\n",
    "    tweet = tweet.strip()\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # return [w.strip(punctuation) for w in tweet.split() if w.strip(punctuation)!='']\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XKYfm1mld6qs"
   },
   "outputs": [],
   "source": [
    "# Define Dataset class which cleans, tokenizes and encodes data\n",
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        # Initialize BERT tokenizer\n",
    "        # Note that I need to specify cache_dir because I'm using a venv\n",
    "        self.tok = BertTokenizer.from_pretrained('bert-base-uncased', cache_dir=Path.cwd()/'venv/lib/python3.8/site-packages')\n",
    "        \n",
    "        # Clean tweets\n",
    "        self.cleaned_tweets = data['tweet'].apply(lambda x: clean_text(x))\n",
    "        \n",
    "        # Truncate and encode tweets, up to max_length of 60\n",
    "        # While this is lower than BERT's max (512), it was chosen for computational speed\n",
    "        self.tweets = list(self.cleaned_tweets.apply(self.tok.encode, max_length=60, truncation=True))\n",
    "        \n",
    "        # Store labels\n",
    "        self.labels = list(data['hate_speech'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.tweets[idx]\n",
    "        label = self.labels[idx]\n",
    "        return tweet, label\n",
    "    \n",
    "# Inspect an example\n",
    "# BD = BERTDataset(train.iloc[:5])\n",
    "# next(iter(BD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SSQx8b3eemem"
   },
   "outputs": [],
   "source": [
    "# Define collate function to be passed to DataLoader\n",
    "def bert_collate(batch):\n",
    "    \n",
    "    # Store batch size\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # Separate tweets and labels\n",
    "    tweets = [t for t, _ in batch]\n",
    "    labels = torch.tensor([l for _, l in batch]).long()\n",
    "    \n",
    "    # Store length of longest tweet in batch\n",
    "    max_len = max(len(t) for t in tweets)\n",
    "    \n",
    "    # Create padded tweet and attention mask tensors\n",
    "    tweets_pad = torch.zeros((batch_size, max_len)).long()\n",
    "    masks_pad = torch.zeros((batch_size, max_len)).long()\n",
    "    for i, t in enumerate(tweets):\n",
    "        tweets_pad[i, :len(t)] = torch.tensor(t)\n",
    "        masks_pad[i, :len(t)] = 1\n",
    "        \n",
    "    return tweets_pad, masks_pad, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "beac97a7df464d22b7a08a53430c19d2",
      "0863fe71758549adafcc0e16fa84b980",
      "b9f34b1c088d44d180a4d28c83de255c",
      "b7a60fc31a354cf3b9322af43f9c88a2",
      "accf3f61d0e14bbe854ac8507aeb54fa",
      "3402fb82d3f14b8590bb7a8791eec958",
      "be7784708ce942f6bcd9688396e90649",
      "faa1e4a884004f2f8fd96979fcb60278",
      "af2511f4b2454ef0b10191e1540c0172",
      "0fe428f8854c44c9b1cfbf6eab8deb7f",
      "260453641bd445be97893d275840b4cb"
     ]
    },
    "id": "Q47ju11IexkY",
    "outputId": "c9016996-0255-4818-c3f4-cb29b6c53749"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beac97a7df464d22b7a08a53430c19d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 s, sys: 105 ms, total: 33.2 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create data sets\n",
    "train_dataset = BERTDataset(train)\n",
    "dev_dataset = BERTDataset(dev)\n",
    "test_dataset = BERTDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1qOFJJdEfIav"
   },
   "outputs": [],
   "source": [
    "# Create data loaders using torch.utils.data.DataLoader class\n",
    "# Using shuffle=True instead of specifying RandomSampler\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, collate_fn=bert_collate, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=100, collate_fn=bert_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, collate_fn=bert_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8AszgigfaMU",
    "outputId": "1406f93b-1b09-401d-bcce-f24fce5e061f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------- Batch 0 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 24761,  2072,  ...,     0,     0,     0],\n",
      "        [  101,  2001,  8534,  ...,     0,     0,     0],\n",
      "        [  101,  2903,  2033,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10166,   999,  ...,     0,     0,     0],\n",
      "        [  101, 11999,  2131,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  4440,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 1 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  1005, 10556,  ...,     0,     0,     0],\n",
      "        [  101, 27829,  2050,  ...,     0,     0,     0],\n",
      "        [  101,  7004, 27829,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5292,  4213,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2055,  ...,     0,     0,     0],\n",
      "        [  101,  2149,  2099,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 2 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2073,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2111,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2031,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2043, 21862,  ...,     0,     0,     0],\n",
      "        [  101,  2029,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 3 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[ 101, 2023, 2003,  ...,    0,    0,    0],\n",
      "        [ 101, 6616, 8292,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 2515,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2035, 1996,  ..., 5675, 2000,  102],\n",
      "        [ 101, 2000, 2050,  ...,    0,    0,    0],\n",
      "        [ 101, 5292, 4213,  ...,    0,    0,    0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 4 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2013,  1996,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2025,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2017,  2056,  ...,     0,     0,     0],\n",
      "        [  101,  2035,  9274,  ...,     0,     0,     0],\n",
      "        [  101, 27829, 22083,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 5 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2300,  6947,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2387,  ...,     0,     0,     0],\n",
      "        [  101,  2035, 20428,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2057,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2138, 11382,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2025,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 6 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  2024,  ...,     0,     0,     0],\n",
      "        [  101, 14071, 10354,  ...,     0,     0,     0],\n",
      "        [  101, 27830, 17650,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2035,  1045,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2123,  ...,     0,     0,     0],\n",
      "        [  101,  2043,  2035,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 7 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2043,  2017,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  1037,  ...,  2149,  2099,   102],\n",
      "        ...,\n",
      "        [  101,  1045,  2031,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  1999,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 8 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n",
      "        [  101,  7910, 14129,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2123,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2909,  2296,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  2139,  ...,     0,     0,     0],\n",
      "        [  101,  4929,  2063,  ...,  2409,  1012,   102]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 9 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  2074,  ...,     0,     0,     0],\n",
      "        [  101, 16215,  2015,  ...,     0,     0,     0],\n",
      "        [  101,  2909,  1012,  ...,   999,   999,   102],\n",
      "        ...,\n",
      "        [  101, 11382,  5332,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  8254,  ...,     0,     0,     0],\n",
      "        [  101,  3398,  2021,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 10 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2023,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2079,  ...,     0,     0,     0],\n",
      "        [  101,  2073,  2003,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1059, 24475,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2074,  ...,     0,     0,     0],\n",
      "        [  101,  2200,  8467,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 11 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[ 101, 2040, 2515,  ...,    0,    0,    0],\n",
      "        [ 101, 2043, 1045,  ...,    0,    0,    0],\n",
      "        [ 101, 1045, 2031,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 3606, 2003,  ...,    0,    0,    0],\n",
      "        [ 101, 1045, 5223,  ...,    0,    0,    0],\n",
      "        [ 101, 2000, 8081,  ...,    0,    0,    0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 12 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2097,  2002,  ...,     0,     0,     0],\n",
      "        [  101,  2200,  5875,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2024,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2054,  5423,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  3841, 11320,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 13 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2023,  4136,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  4618,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  2144,  4274,  ...,     0,     0,     0],\n",
      "        [  101,  1048,  2863,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 14 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2216, 11320,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2064,  ...,     0,     0,     0],\n",
      "        [  101, 11333,  7834,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8934, 10179,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  3277,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2003,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 15 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101, 11085, 10354,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2111,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2054,  3047,  ...,     0,     0,     0],\n",
      "        [  101,  2200,  2919,  ...,     0,     0,     0],\n",
      "        [  101,  8807, 22822,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 16 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2200,  2204,  ...,     0,     0,     0],\n",
      "        [  101,  4050,  2069,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2035,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2054,  2055,  ...,     0,     0,     0],\n",
      "        [  101,  2035, 11884,  ...,     0,     0,     0],\n",
      "        [  101,  5292,  4213,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 17 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[ 101, 5292, 4213,  ...,    0,    0,    0],\n",
      "        [ 101, 2017, 2024,  ...,    0,    0,    0],\n",
      "        [ 101, 2057, 2556,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2017, 2812,  ...,    0,    0,    0],\n",
      "        [ 101, 2057, 2024,  ...,    0,    0,    0],\n",
      "        [ 101, 3649, 6433,  ...,    0,    0,    0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 18 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[ 101, 2057, 2024,  ...,    0,    0,    0],\n",
      "        [ 101, 2057, 2323,  ...,    0,    0,    0],\n",
      "        [ 101, 2017, 2024,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2017, 5223,  ...,    0,    0,    0],\n",
      "        [ 101, 2040, 2003,  ...,    0,    0,    0],\n",
      "        [ 101, 8807, 2964,  ...,    0,    0,    0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 19 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[ 101, 2017, 4364,  ...,    0,    0,    0],\n",
      "        [ 101, 3524, 4183,  ...,    0,    0,    0],\n",
      "        [ 101, 2017, 2024,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 4826, 2027,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 3736,  ...,    0,    0,    0],\n",
      "        [ 101, 2149, 2099,  ...,    0,    0,    0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 20 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  2031,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2108,  1001,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  2866,  2072,  ...,     0,     0,     0],\n",
      "        [  101,  9033, 28954,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 21 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 27829,  2050,  ...,     0,     0,     0],\n",
      "        [  101, 27829, 22083,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  8807,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 22 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2748,  2995,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2020,  ...,     0,     0,     0],\n",
      "        [  101, 11333,  9759,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2057,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  2995,  4661,  ...,     0,     0,     0],\n",
      "        [  101,  2097,  2002,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 23 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2096,  1045,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,  6895, 10895,   102],\n",
      "        [  101,  2054,  2015,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10166,  1012,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2031,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 23270,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 24 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2339,  2102,  ...,     0,     0,     0],\n",
      "        [  101, 28194,  2226,  ...,     0,     0,     0],\n",
      "        [  101,  2043,  2097,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3251,  2049,  ...,     0,     0,     0],\n",
      "        [  101,  2073,  2003,  ...,     0,     0,     0],\n",
      "        [  101, 25188,  2102,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 25 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  9378, 22254,  ...,     0,     0,     0],\n",
      "        [  101,  2092,  2027,  ...,     0,     0,     0],\n",
      "        [  101, 11333, 25787,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16215, 20939,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101, 10556,  5092,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 26 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2057,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2130,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2131,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2216,  2542,  ...,     0,     0,     0],\n",
      "        [  101,  7910, 14129,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  1037,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 27 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2057, 11333,  ...,     0,     0,     0],\n",
      "        [  101,  2022,  6047,  ...,     0,     0,     0],\n",
      "        [  101, 19045, 11382,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2144,  2343,  ...,     0,     0,     0],\n",
      "        [  101,  5292,  4213,  ...,     0,     0,     0],\n",
      "        [  101,  2007, 27571,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 28 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2054,  2052,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2323,  ...,     0,     0,     0],\n",
      "        [  101,  7658, 19042,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10722,  7834,  ...,     0,     0,     0],\n",
      "        [  101,  1057,  2064,  ...,     0,     0,     0],\n",
      "        [  101,  3398,  2005,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 29 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2995,  4283,  ...,     0,     0,     0],\n",
      "        [  101, 24835,  1998,  ...,     0,     0,     0],\n",
      "        [  101,  2748,  2035,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  2069,  ...,     0,     0,     0],\n",
      "        [  101,  2022, 27225,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  2024,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 30 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  9471,  ...,     0,     0,     0],\n",
      "        [  101,  8807, 15831,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1045,  2031,  ...,     0,     0,     0],\n",
      "        [  101,  6616,  7623,  ...,     0,     0,     0],\n",
      "        [  101,  2043,  4903,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 31 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  6819, 14971,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  3168,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2097,  ...,     0,     0,     0],\n",
      "        [  101,  2664,  3098,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 32 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  5292,  4213,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2339,  2069,  ...,     0,     0,     0],\n",
      "        [  101, 28194,  4017,  ...,     0,     0,     0],\n",
      "        [  101, 10556, 27052,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 33 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2012,  2072,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2113,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2965,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11210,  2002,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2079,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2442,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 34 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2057, 17704,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  7910, 14129,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2149,  2099,  ...,     0,     0,     0],\n",
      "        [  101,  2000,  1996,  ...,     0,     0,     0],\n",
      "        [  101,  8807,  9499,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 35 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  7221,  2050,  ...,     0,     0,     0],\n",
      "        [  101,  7226,  3597,  ...,     0,     0,     0],\n",
      "        [  101, 11333,  9759,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2520, 21766,  ...,     0,     0,     0],\n",
      "        [  101,  8934,  2226,  ...,     0,     0,     0],\n",
      "        [  101, 16278,  2097,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 36 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 24761,  2072,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2145,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2562,  2206,  ...,     0,     0,     0],\n",
      "        [  101,  1060,  2094,  ...,     0,     0,     0],\n",
      "        [  101,  9467,  2006,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 37 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[ 101, 2057, 2196,  ...,    0,    0,    0],\n",
      "        [ 101, 2339, 2038,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 1037,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2054, 1997,  ...,    0,    0,    0],\n",
      "        [ 101, 2043, 1045,  ...,    0,    0,    0],\n",
      "        [ 101, 2073, 2003,  ...,    0,    0,    0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 38 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2205,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2007, 18079,  ...,     0,     0,     0],\n",
      "        [  101,  2035,  1999,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2323,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 39 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  2812,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2113,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2057,  2123,  ...,     0,     0,     0],\n",
      "        [  101,  2216, 11382,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 40 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 10556,  7770,  ...,     0,     0,     0],\n",
      "        [  101, 21934,  3676,  ...,     0,     0,     0],\n",
      "        [  101,  5171,  1997,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  2000,  9944,  ...,     0,     0,     0],\n",
      "        [  101,  2043,  2619,  ...,  1999,  1996,   102]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 41 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 21873,   999,  ...,  7178,  2945,   102],\n",
      "        [  101,  5949,  1997,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2442,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11419,  2011,  ..., 14129,  7606,   102],\n",
      "        [  101,  2029,  3604,  ...,     0,     0,     0],\n",
      "        [  101,  6919,  2140,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 42 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11333, 25787,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2031,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5332,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2054,  2785,  ...,     0,     0,     0],\n",
      "        [  101,  2000,  2023,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  4364,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 43 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2216,  2040,  ...,     0,     0,     0],\n",
      "        [  101,  3251,  2057,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2012,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10722, 22332,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2065,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2253,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 44 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2057,  3685,  ...,     0,     0,     0],\n",
      "        [  101, 13619,  2072,  ...,     0,     0,     0],\n",
      "        [  101,  2520, 10556,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 27829, 22083,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  1001,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ..., 11382,  5283,   102]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 45 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  1048,  2863,  ...,     0,     0,     0],\n",
      "        [  101, 27793,  2102,  ...,     0,     0,     0],\n",
      "        [  101,  2073,  2003,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  4364,  ...,     0,     0,     0],\n",
      "        [  101,  8814,  2094,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 46 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  8038, 13970,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2985,  ...,     0,     0,     0],\n",
      "        [  101, 10722, 24238,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8670, 18142,  ...,     0,     0,     0],\n",
      "        [  101,  2035, 20428,  ...,     0,     0,     0],\n",
      "        [  101,  2383,  2419,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 47 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  3524,  1037,  ...,     0,     0,     0],\n",
      "        [  101, 10166, 12043,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2057,  2442,  ...,     0,     0,     0],\n",
      "        [  101,  1057,  2031,  ...,     0,     0,     0],\n",
      "        [  101,  1048,  2863,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 48 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  2069,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  4503,  ...,     0,     0,     0],\n",
      "        [  101, 28981,  5403,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2057, 27829,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2023, 27793,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 49 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2057,  2323,  ...,     0,     0,     0],\n",
      "        [  101, 11333, 25787,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1045,  2031,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  1996,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 50 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2054,  2055,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  2035,  2026,  ...,   102,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  4895, 18150,  ...,     0,     0,     0],\n",
      "        [  101, 27829, 22083,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 51 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2149,  2099,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2122, 11320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2017,  2113,  ...,     0,     0,     0],\n",
      "        [  101,  2200,  2574,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 52 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11333,  3211,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  7910, 14129,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1057,  2081,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  2043,  2049,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 53 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2007,  2023,  ...,     0,     0,     0],\n",
      "        [  101,  2138, 21934,  ...,     0,     0,     0],\n",
      "        [  101,  2023, 11382,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9444,  2730,  ...,     0,     0,     0],\n",
      "        [  101,  2216,  2111,  ...,     0,     0,     0],\n",
      "        [  101, 27829, 22083,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 54 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2158,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2017,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  8038,  2361,  ...,     0,     0,     0],\n",
      "        [  101,  2300, 16018,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 55 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  4983,  2017,  ...,     0,     0,     0],\n",
      "        [  101,  1056, 28394,  ...,     0,     0,     0],\n",
      "        [  101,  2077,  2017,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  ...,     0,     0,     0],\n",
      "        [  101, 10556, 18477,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 56 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2144,  2043,  ...,     0,     0,     0],\n",
      "        [  101,  2017, 11382,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2055,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,  2406,   102,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 57 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2115,  2589,  ...,     0,     0,     0],\n",
      "        [  101,  2000,  2912,  ...,     0,     0,     0],\n",
      "        [  101, 11333,  7507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11333, 25787,  ...,     0,     0,     0],\n",
      "        [  101, 20948, 27593,  ...,     0,     0,     0],\n",
      "        [  101, 24185,  2072,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 58 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 27125, 26195,  ...,     0,     0,     0],\n",
      "        [  101, 27829,  3676,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  6968,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1005, 14841,  ...,     0,     0,     0],\n",
      "        [  101,  1057,  2425,  ...,     0,     0,     0],\n",
      "        [  101,  2017, 18067,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 59 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  2215,  ...,     0,     0,     0],\n",
      "        [  101,  2092,  2589,  ...,     0,     0,     0],\n",
      "        [  101,  2200,  8807,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2017,  2288,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2149,  2099,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 60 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2205, 15896,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2079,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1057,  2323,  ...,     0,     0,     0],\n",
      "        [  101, 20948, 27593,  ...,     0,     0,     0],\n",
      "        [  101,  5292,  4213,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 61 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017,  1005,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101, 27829,  2050,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3174,  1011,  ...,     0,     0,     0],\n",
      "        [  101,  2339,  2134,  ...,     0,     0,     0],\n",
      "        [  101,  5939,  5521,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 62 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[ 101, 2057, 2113,  ...,    0,    0,    0],\n",
      "        [ 101, 2216, 5003,  ...,    0,    0,    0],\n",
      "        [ 101, 2562, 4169,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2096, 2003,  ...,    0,    0,    0],\n",
      "        [ 101, 2748, 1024,  ...,    0,    0,    0],\n",
      "        [ 101, 2029, 2028,  ...,    0,    0,    0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 63 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 14477, 16656,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2043,  2356,  ...,  3736,   102,     0],\n",
      "        ...,\n",
      "        [  101,  2664,  1996,  ...,     0,     0,     0],\n",
      "        [  101,  1056, 28394,  ...,     0,     0,     0],\n",
      "        [  101,  2073,  2003,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 64 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101, 11333, 25787,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0],\n",
      "        [  101,  2035,  6946,  ...,  2023,  6752,   102],\n",
      "        ...,\n",
      "        [  101,  2023,  2050,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2758,  ...,     0,     0,     0],\n",
      "        [  101,  3666,  2149,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 65 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2023, 11382,  ...,     0,     0,     0],\n",
      "        [  101, 23068, 12848,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  7910, 14129,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 66 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  1057,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  2029,  7938,  ...,     0,     0,     0],\n",
      "        [  101,  3404,  2378,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2029, 25353,  ...,     0,     0,     0],\n",
      "        [  101,  2035,  1996,  ...,     0,     0,     0],\n",
      "        [  101,  2127, 14163,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 67 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2748,  1012,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  2315,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11382,  5332,  ...,     0,     0,     0],\n",
      "        [  101,  2115, 16411,  ...,     0,     0,     0],\n",
      "        [  101,  7188,  1045,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 68 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  4895,  6895,  ...,     0,     0,     0],\n",
      "        [  101, 27883,  2524,  ..., 13319,  1001,   102],\n",
      "        [  101,  2057,  3582,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2017,  3685,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  2149,  2099,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 69 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2339,  2079,  ...,     0,     0,     0],\n",
      "        [  101,  2054, 11376,  ...,     0,     0,     0],\n",
      "        [  101,  2093,  4268,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2149,  2099,  ...,     0,     0,     0],\n",
      "        [  101, 11320, 17915,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 70 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2017, 20242,  ...,     0,     0,     0],\n",
      "        [  101,  2000,  2022,  ...,     0,     0,     0],\n",
      "        [  101,  1048,  2863,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2057,  6396,  ...,     0,     0,     0],\n",
      "        [  101,  2096,  3071,  ...,     0,     0,     0],\n",
      "        [  101, 11382,  5283,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 71 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2040,  2409,  ...,     0,     0,     0],\n",
      "        [  101,  4079, 16914,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2000,  2147,  ...,     0,     0,     0],\n",
      "        [  101, 10722,  7834,  ...,     0,     0,     0],\n",
      "        [  101,  2149,  2099,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 72 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  6870,  7181,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2035,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  2134,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1057,  9759,  ...,     0,     0,     0],\n",
      "        [  101, 11382, 15042,  ...,     0,     0,     0],\n",
      "        [  101, 14071,  4215,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0])\n",
      "\n",
      "\n",
      "--------------------- Batch 73 ---------------------\n",
      "\n",
      "There are 100 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2149,  2099,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  2056,  ...,     0,     0,     0],\n",
      "        [  101, 28194,  4817,  ...,   102,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  6057,  2518,  ...,     0,     0,     0]])\n",
      "There are 100 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "\n",
      "\n",
      "--------------------- Batch 74 ---------------------\n",
      "\n",
      "There are 83 encoded tweets in this batch.\n",
      "Tweets (encoded):  tensor([[  101,  2043, 11320,  ...,     0,     0,     0],\n",
      "        [  101, 11320,  2891,  ...,     0,     0,     0],\n",
      "        [  101,  2040,  9631,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2149,  2099,  ...,     0,     0,     0],\n",
      "        [  101,  2073,  2024,  ...,     0,     0,     0],\n",
      "        [  101,  2035, 11320,  ...,     0,     0,     0]])\n",
      "There are 83 encoded labels in this batch. Here they are: \n",
      "Labels:  tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Inspect\n",
    "for (idx, batch) in enumerate(train_loader):\n",
    "\n",
    "    print(f'\\n\\n--------------------- Batch {idx} ---------------------\\n')\n",
    "    \n",
    "    # Print the text\n",
    "    print(f\"There are {len(batch[0])} encoded tweets in this batch.\")\n",
    "    print('Tweets (encoded): ', batch[0])\n",
    "\n",
    "    # Print the label\n",
    "    print(f\"There are {len(batch[2])} encoded labels in this batch. Here they are: \")\n",
    "    print('Labels: ', batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UZbA7B7sfrr9"
   },
   "outputs": [],
   "source": [
    "# Define BERT classifier\n",
    "class BERTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Specify network layers\n",
    "        # Note that I need to specify cache as I'm using a venv\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased', cache_dir=Path.cwd()/'venv/lib/python3.8/site-packages')\n",
    "        self.linear = nn.Linear(768, 4)\n",
    "        \n",
    "        # Define dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # Freeze BERT layers\n",
    "        for n, p in self.bert.named_parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def forward(self, tweets, masks):\n",
    "        \n",
    "        # Define flow of tensors through the network\n",
    "        output_bert = self.bert(tweets, attention_mask=masks)[0].mean(axis=1)\n",
    "        return self.linear(self.dropout(output_bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning the pretrained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f0bb1b4c74114d56b5d5b176fc98384c",
      "bd5d77ed43354ca2b5857f24bfe13ca7",
      "7b18e374227b4c728c8d8675f3171375",
      "991011078e58471383b47182d2145178",
      "742464a65774415f942dd8c0a85164f8",
      "c6738d57a37b42ccb886331b3888f54a",
      "8f27d435b8104d2bab39fca1f5d51b8d",
      "56e093c266be4f6396a543e1bed4f30b",
      "9ef31ec6c84a4b42813ceefb346f4265",
      "00ea5005542f4c06a25749b3c18dbdf2",
      "4b48ae98b05145e2b7356d25583e8cd8",
      "3b43963a3c8d4b0f9317589fd14fc841",
      "ef44c5a23ee94125ba8ab768a7a0c29a",
      "24efe97072944742a97859af95b612f7",
      "9869f197305b4252a3ad98c14ac48640",
      "83aacd0aec774802846fd63d745b5214",
      "27e61c05a8014a53b48150124597d168",
      "c51c4b5ba2de439b82e695fb76f34fd1",
      "f471af6687684bc996c945bac8703cf2",
      "2ddb498845904a8ea40766735617ae99",
      "265b67a2d4c24e18a4f830e5deef6531",
      "b4dd8cb957864d52a634b6fba88ebcd8"
     ]
    },
    "id": "AY_vBKasf6ug",
    "outputId": "8bd2fc7e-073b-4a8f-da84-557d8b2d826a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bb1b4c74114d56b5d5b176fc98384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b43963a3c8d4b0f9317589fd14fc841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise model\n",
    "model = BERTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gPiZsA1qgEXs"
   },
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lzurD04wgPng"
   },
   "outputs": [],
   "source": [
    "# Define optimiser, objective function and epochs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WV3eZE-tgXAc",
    "outputId": "1419340f-374f-488c-bd21-afd929cf6a34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:24<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 1 epoch(s): 0.6923693705732995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:22<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 2 epoch(s): 0.6955766403848723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:23<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 3 epoch(s): 0.685553922223707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:23<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 4 epoch(s): 0.6744621141253508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:23<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 5 epoch(s): 0.6999866363757851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:23<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 6 epoch(s): 0.6967793665642122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:23<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 7 epoch(s): 0.6957102766270212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:23<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 8 epoch(s): 0.6792730188427102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:23<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 9 epoch(s): 0.696913002806361\n",
      "CPU times: user 7min, sys: 1.04 s, total: 7min 1s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train model\n",
    "for epoch_i in range(1, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "        \n",
    "    # Put model into training mode. This is necessary so that the `Dropout`\n",
    "    # layers are activated. \n",
    "    model.train()\n",
    "    \n",
    "    # For each batch of the training data...\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        # Step 1. Since PyTorch accumulates gradients, clear any previously\n",
    "        # calculated gradients before performing a backward pass.\n",
    "        # PyTorch doesn't do this automatically because it can be useful while\n",
    "        # training RNNs.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 2. Extract data and move to device.\n",
    "        tweets, masks, labels = [t.to(device) for t in batch]\n",
    "        \n",
    "        # Step 3. Forward pass - note that calling `model()` will in turn call\n",
    "        # the model's `forward()` function.\n",
    "        output = model(tweets, masks)\n",
    "        \n",
    "        # Step 4. Compute loss.\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Step 5. Perform backward pass to calculate gradients wrt each w and b term. \n",
    "        loss.backward()\n",
    "        \n",
    "        # Step 6. Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # Step 7. Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    # Put model into evaluation mode, thereby deactivating Dropout layer.\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = list()\n",
    "    y_pred = list()\n",
    "    \n",
    "    with torch.no_grad(): # We no longer need it to store computation graph.\n",
    "        for batch in dev_loader:\n",
    "            tweets, masks, labels = [t.to(device) for t in batch]\n",
    "            output = model(tweets, masks)\n",
    "            max_output = output.argmax(dim=1)\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(max_output.tolist())\n",
    "            \n",
    "    print(f\"Accuracy after {epoch_i} epoch(s): {accuracy_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "id": "YhMUffZYk-8X",
    "outputId": "a7370453-4131-45a2-ff40-4df4868ac307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.61\n",
      "\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.63      0.75     39448\n",
      "           1       0.25      0.78      0.38      7483\n",
      "           2       0.00      0.00      0.00      2460\n",
      "           3       0.00      0.00      0.00       770\n",
      "           4       0.00      0.00      0.00        13\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61     50175\n",
      "   macro avg       0.20      0.24      0.19     50175\n",
      "weighted avg       0.77      0.61      0.65     50175\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# _homogenize ensures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m#  - all(len(x) == len(index) for x in arrays)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             )\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \"\"\"\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (6) does not match length of index (2)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ========================================\n",
    "#               Evaluation\n",
    "# ========================================\n",
    "\n",
    "# Evaluate model on test data\n",
    "model.eval()\n",
    "\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        tweets, masks, labels = [t.to(device) for t in batch]\n",
    "        output = model(tweets, masks)\n",
    "        max_output = output.argmax(dim=1)\n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred.extend(max_output.tolist())\n",
    "\n",
    "print('Test accuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))\n",
    "print('\\nClassification report: \\n', classification_report(y_true, y_pred))\n",
    "print('\\nConfusion matrix: \\n')\n",
    "display(pd.DataFrame({\"Predicted: hate_speech\": confusion_matrix(y_true, y_pred)[:, 0], \n",
    "              \"Predicted: offensive_language\": confusion_matrix(y_true, y_pred)[:, 1]},\n",
    "             index=['Actual: hate_speech', 'Actual: offensive_language']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPP36TyA4D55"
   },
   "source": [
    "### Comparison to baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JR_AJtaA4MNY",
    "outputId": "addfa301-5e05-4098-a3e2-053af1c84566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88     39448\n",
      "           1       0.00      0.00      0.00      7483\n",
      "           2       0.00      0.00      0.00      2460\n",
      "           3       0.00      0.00      0.00       770\n",
      "           4       0.00      0.00      0.00        13\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.79     50175\n",
      "   macro avg       0.13      0.17      0.15     50175\n",
      "weighted avg       0.62      0.79      0.69     50175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict all majority class\n",
    "y_pred = [0] * len(df)\n",
    "y_true = df['hate_speech']\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86_e9SJD4lkp",
    "outputId": "149b1743-b5e5-453f-f605-ef34be4a57a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88     39448\n",
      "           1       0.00      0.00      0.00      7483\n",
      "           2       0.00      0.00      0.00      2460\n",
      "           3       0.00      0.00      0.00       770\n",
      "           4       0.00      0.00      0.00        13\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.79     50175\n",
      "   macro avg       0.13      0.17      0.15     50175\n",
      "weighted avg       0.62      0.79      0.69     50175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Probabilistic guess\n",
    "maj_prob = df['hate_speech'].value_counts(normalize=True).values\n",
    "#y_pred = [0]*int(maj_prob*len(df)) + [1]*int(maj_prob*len(df))\n",
    "y_pred = random.sample(y_pred, len(y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBKz1mcI9IiA"
   },
   "source": [
    "Naïve Bayes BoW classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lqbjzPcA9LyR"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_s_ivZvH9sjE"
   },
   "outputs": [],
   "source": [
    "# Generate vocabs\n",
    "n_total, vocab, distinct_mentions = get_vocabs(train)\n",
    "\n",
    "# Generate MI list\n",
    "mi_list = sorted([(mi(w, distinct_mentions, n_total), w) for w in set(vocab[1]).union(set(vocab[0]))], reverse=True)\n",
    "\n",
    "# Estimate P(c_i), the probability of class c_i\n",
    "categories = [0, 1]\n",
    "prob_class = dict()\n",
    "total_tweets = len(train)\n",
    "for c_i in categories:\n",
    "    prob_class[c_i] = len(train[train['HOF']==c_i]) / total_tweets\n",
    "\n",
    "# Get predictions on test set using arbitrary values for n_features and smoothing_alpha\n",
    "# This is just to test that it works\n",
    "probs = naive_bayes_additive_smoothing_feature_selection(vocab, categories, 0.25, 1000, mi_list)\n",
    "labels, predictions = get_nb_predictions(categories, test, probs, prob_class)\n",
    "print(classification_report(labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ea5005542f4c06a25749b3c18dbdf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0863fe71758549adafcc0e16fa84b980": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3402fb82d3f14b8590bb7a8791eec958",
      "placeholder": "​",
      "style": "IPY_MODEL_be7784708ce942f6bcd9688396e90649",
      "value": "Downloading: 100%"
     }
    },
    "0fe428f8854c44c9b1cfbf6eab8deb7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24efe97072944742a97859af95b612f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f471af6687684bc996c945bac8703cf2",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ddb498845904a8ea40766735617ae99",
      "value": 440473133
     }
    },
    "260453641bd445be97893d275840b4cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "265b67a2d4c24e18a4f830e5deef6531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27e61c05a8014a53b48150124597d168": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ddb498845904a8ea40766735617ae99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3402fb82d3f14b8590bb7a8791eec958": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b43963a3c8d4b0f9317589fd14fc841": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef44c5a23ee94125ba8ab768a7a0c29a",
       "IPY_MODEL_24efe97072944742a97859af95b612f7",
       "IPY_MODEL_9869f197305b4252a3ad98c14ac48640"
      ],
      "layout": "IPY_MODEL_83aacd0aec774802846fd63d745b5214"
     }
    },
    "4b48ae98b05145e2b7356d25583e8cd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56e093c266be4f6396a543e1bed4f30b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "742464a65774415f942dd8c0a85164f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b18e374227b4c728c8d8675f3171375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56e093c266be4f6396a543e1bed4f30b",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ef31ec6c84a4b42813ceefb346f4265",
      "value": 570
     }
    },
    "83aacd0aec774802846fd63d745b5214": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f27d435b8104d2bab39fca1f5d51b8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9869f197305b4252a3ad98c14ac48640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_265b67a2d4c24e18a4f830e5deef6531",
      "placeholder": "​",
      "style": "IPY_MODEL_b4dd8cb957864d52a634b6fba88ebcd8",
      "value": " 440M/440M [00:06&lt;00:00, 48.1MB/s]"
     }
    },
    "991011078e58471383b47182d2145178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00ea5005542f4c06a25749b3c18dbdf2",
      "placeholder": "​",
      "style": "IPY_MODEL_4b48ae98b05145e2b7356d25583e8cd8",
      "value": " 570/570 [00:00&lt;00:00, 31.0kB/s]"
     }
    },
    "9ef31ec6c84a4b42813ceefb346f4265": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "accf3f61d0e14bbe854ac8507aeb54fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af2511f4b2454ef0b10191e1540c0172": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4dd8cb957864d52a634b6fba88ebcd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7a60fc31a354cf3b9322af43f9c88a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe428f8854c44c9b1cfbf6eab8deb7f",
      "placeholder": "​",
      "style": "IPY_MODEL_260453641bd445be97893d275840b4cb",
      "value": " 232k/232k [00:00&lt;00:00, 2.84MB/s]"
     }
    },
    "b9f34b1c088d44d180a4d28c83de255c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_faa1e4a884004f2f8fd96979fcb60278",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af2511f4b2454ef0b10191e1540c0172",
      "value": 231508
     }
    },
    "bd5d77ed43354ca2b5857f24bfe13ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6738d57a37b42ccb886331b3888f54a",
      "placeholder": "​",
      "style": "IPY_MODEL_8f27d435b8104d2bab39fca1f5d51b8d",
      "value": "Downloading: 100%"
     }
    },
    "be7784708ce942f6bcd9688396e90649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "beac97a7df464d22b7a08a53430c19d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0863fe71758549adafcc0e16fa84b980",
       "IPY_MODEL_b9f34b1c088d44d180a4d28c83de255c",
       "IPY_MODEL_b7a60fc31a354cf3b9322af43f9c88a2"
      ],
      "layout": "IPY_MODEL_accf3f61d0e14bbe854ac8507aeb54fa"
     }
    },
    "c51c4b5ba2de439b82e695fb76f34fd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6738d57a37b42ccb886331b3888f54a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef44c5a23ee94125ba8ab768a7a0c29a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27e61c05a8014a53b48150124597d168",
      "placeholder": "​",
      "style": "IPY_MODEL_c51c4b5ba2de439b82e695fb76f34fd1",
      "value": "Downloading: 100%"
     }
    },
    "f0bb1b4c74114d56b5d5b176fc98384c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd5d77ed43354ca2b5857f24bfe13ca7",
       "IPY_MODEL_7b18e374227b4c728c8d8675f3171375",
       "IPY_MODEL_991011078e58471383b47182d2145178"
      ],
      "layout": "IPY_MODEL_742464a65774415f942dd8c0a85164f8"
     }
    },
    "f471af6687684bc996c945bac8703cf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faa1e4a884004f2f8fd96979fcb60278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
